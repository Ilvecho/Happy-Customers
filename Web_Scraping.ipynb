{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNs5g66VkU8pxl3FsbTvDy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilvecho/Happy-Customers/blob/main/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install Scrapy"
      ],
      "metadata": {
        "id": "B9vb5_2zbMn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hj3pIClta0CH",
        "outputId": "a59789ad-180f-448a-bdda-10e52e24c639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "\n",
        "from google.colab import files,drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the spider to crawl the desired URLs"
      ],
      "metadata": {
        "id": "-oeYbgGFcgLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HrSpider(scrapy.Spider):\n",
        "  name = 'hr_spider'\n",
        "\n",
        "  def start_requests(self):\n",
        "    urls = ['https://www.getimpactly.com/post/hr-compliance-checklist']\n",
        "\n",
        "    for url in urls:\n",
        "      yield scrapy.Request(url=url, callback=self.parse)\n",
        "\n",
        "  # We want to preserve the order of the paragraphs and list items\n",
        "  def combine_content(self, paragraphs, titles, list_items, link_text):\n",
        "    combined_content = []\n",
        "\n",
        "    # Add paragraphs and list items in the correct order\n",
        "    while paragraphs or titles or list_items or link_text:\n",
        "      if paragraphs:\n",
        "        combined_content.append(paragraphs.pop(0))\n",
        "      elif titles:\n",
        "        combined_content.append(titles.pop(0))\n",
        "      elif list_items:\n",
        "        combined_content.append(list_items.pop(0))\n",
        "      elif link_text:\n",
        "        combined_content.append(link_text.pop(0))\n",
        "\n",
        "    return combined_content\n",
        "\n",
        "  def parse(self, response):\n",
        "    output_text = ''\n",
        "    # Extract content from <p> tags\n",
        "    paragraphs = response.css('p::text').extract()\n",
        "\n",
        "    # Extract content from <h2> tags\n",
        "    titles = response.css('h2::text').extract()\n",
        "\n",
        "    # Extract content from <li> tags\n",
        "    list_items = response.css('li::text').extract()\n",
        "\n",
        "    # Extract the text of links in the body -> XPath //p//a/text()\n",
        "    link_text = response.xpath('//p/a/text()').extract()\n",
        "\n",
        "    # Combine paragraphs and list items in the correct order\n",
        "    combined_content = self.combine_content(paragraphs, titles, list_items, link_text)\n",
        "\n",
        "    # Do something with the extracted content (e.g., print it)\n",
        "    for content in combined_content:\n",
        "      print(content)\n",
        "      output_text = output_text + '\\n' + content\n",
        "\n",
        "    # Save the text in a file\n",
        "    with open(r'/content/gdrive/MyDrive/hr_content.txt', 'w') as text_file:\n",
        "      text_file.write(output_text)\n",
        "      text_file.close()\n"
      ],
      "metadata": {
        "id": "ljh3wXNGcjs0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process = CrawlerProcess()  # Look what Scrapy settings are # settings={'FEEDS': {'item.txt': {'format': 'txt'}}}\n",
        "process.crawl(HrSpider)\n",
        "process.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC1ZNABUe4AV",
        "outputId": "aa8810d6-eedc-40d9-a1ac-06e083081789"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:scrapy.utils.log:Scrapy 2.11.0 started (bot: scrapybot)\n",
            "2024-01-21 11:05:17 [scrapy.utils.log] INFO: Scrapy 2.11.0 started (bot: scrapybot)\n",
            "INFO:scrapy.utils.log:Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0], pyOpenSSL 23.3.0 (OpenSSL 3.1.4 24 Oct 2023), cryptography 41.0.7, Platform Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "2024-01-21 11:05:17 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0], pyOpenSSL 23.3.0 (OpenSSL 3.1.4 24 Oct 2023), cryptography 41.0.7, Platform Linux-6.1.58+-x86_64-with-glibc2.35\n",
            "INFO:scrapy.addons:Enabled addons:\n",
            "[]\n",
            "2024-01-21 11:05:17 [scrapy.addons] INFO: Enabled addons:\n",
            "[]\n",
            "/usr/local/lib/python3.10/dist-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
            "\n",
            "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
            "\n",
            "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
            "  return cls(crawler)\n",
            "DEBUG:scrapy.utils.log:Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "2024-01-21 11:05:17 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
            "INFO:scrapy.extensions.telnet:Telnet Password: 687f6c7da0a30dcb\n",
            "2024-01-21 11:05:18 [scrapy.extensions.telnet] INFO: Telnet Password: 687f6c7da0a30dcb\n",
            "INFO:scrapy.middleware:Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "2024-01-21 11:05:18 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.logstats.LogStats']\n",
            "INFO:scrapy.crawler:Overridden settings:\n",
            "{}\n",
            "2024-01-21 11:05:18 [scrapy.crawler] INFO: Overridden settings:\n",
            "{}\n",
            "INFO:scrapy.middleware:Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-01-21 11:05:18 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "INFO:scrapy.middleware:Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-01-21 11:05:18 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "INFO:scrapy.middleware:Enabled item pipelines:\n",
            "[]\n",
            "2024-01-21 11:05:18 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "INFO:scrapy.core.engine:Spider opened\n",
            "2024-01-21 11:05:18 [scrapy.core.engine] INFO: Spider opened\n",
            "INFO:scrapy.extensions.logstats:Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-01-21 11:05:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "INFO:scrapy.extensions.telnet:Telnet console listening on 127.0.0.1:6023\n",
            "2024-01-21 11:05:18 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "DEBUG:scrapy.core.engine:Crawled (200) <GET https://www.getimpactly.com/post/hr-compliance-checklist> (referer: None)\n",
            "2024-01-21 11:05:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.getimpactly.com/post/hr-compliance-checklist> (referer: None)\n",
            "INFO:scrapy.core.engine:Closing spider (finished)\n",
            "2024-01-21 11:05:18 [scrapy.core.engine] INFO: Closing spider (finished)\n",
            "INFO:scrapy.statscollectors:Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 248,\n",
            " 'downloader/request_count': 1,\n",
            " 'downloader/request_method_count/GET': 1,\n",
            " 'downloader/response_bytes': 19811,\n",
            " 'downloader/response_count': 1,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'elapsed_time_seconds': 0.521064,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 1, 21, 11, 5, 18, 872693, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 74924,\n",
            " 'httpcompression/response_count': 1,\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 187867136,\n",
            " 'memusage/startup': 187867136,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 1, 21, 11, 5, 18, 351629, tzinfo=datetime.timezone.utc)}\n",
            "2024-01-21 11:05:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
            "{'downloader/request_bytes': 248,\n",
            " 'downloader/request_count': 1,\n",
            " 'downloader/request_method_count/GET': 1,\n",
            " 'downloader/response_bytes': 19811,\n",
            " 'downloader/response_count': 1,\n",
            " 'downloader/response_status_count/200': 1,\n",
            " 'elapsed_time_seconds': 0.521064,\n",
            " 'finish_reason': 'finished',\n",
            " 'finish_time': datetime.datetime(2024, 1, 21, 11, 5, 18, 872693, tzinfo=datetime.timezone.utc),\n",
            " 'httpcompression/response_bytes': 74924,\n",
            " 'httpcompression/response_count': 1,\n",
            " 'log_count/DEBUG': 2,\n",
            " 'log_count/INFO': 10,\n",
            " 'memusage/max': 187867136,\n",
            " 'memusage/startup': 187867136,\n",
            " 'response_received_count': 1,\n",
            " 'scheduler/dequeued': 1,\n",
            " 'scheduler/dequeued/memory': 1,\n",
            " 'scheduler/enqueued': 1,\n",
            " 'scheduler/enqueued/memory': 1,\n",
            " 'start_time': datetime.datetime(2024, 1, 21, 11, 5, 18, 351629, tzinfo=datetime.timezone.utc)}\n",
            "INFO:scrapy.core.engine:Spider closed (finished)\n",
            "2024-01-21 11:05:18 [scrapy.core.engine] INFO: Spider closed (finished)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An HR compliance checklist is important for the proper functioning of an organization. HR compliance is defined as the responsibility of the business to abide by and follow the working standards set out by the employment facility. An HR compliance checklist is a systematically organized checklist that provides a list of tasks that need to be completed. Human resource specialists use it to prepare for an HR audit.\n",
            "Compliance is required in the Human Resources department to define policies and procedures for ensuring that your employment and work practices signify a thorough understanding of all applicable laws, rules, and regulations while simultaneously also being aware of the company's larger objectives.\n",
            "HR compliance is considered to be mandatory for the following reasons:\n",
            "HR compliance officers need to ensure that every individual working in the company follows the policies and guidelines. They usually work alongside a dedicated HR compliance team for handling these regulations and being at the center of a smooth-functioning organization.\n",
            "These operational standards set up by employment law may affect the system, policies, and documentation, so the officers need to follow a proactive approach to ensure that the system meets all of its legal obligations.\n",
            "Here is a checklist for HR compliance:\n",
            "The \n",
            " should begin with including details and information regarding recruiting and interviewing processes. This is required for large and small businesses and must be compliant with the Americans with Disabilities Act and the Fair Employment and Housing Act. All interview questions should be outlined properly to process the information on the current job application and the job descriptions.\n",
            "It is crucial to ensure whether an employee is a proper fit for the company, and the focus needs to be more on their area of responsibility. The procedure needs to be properly executed by including offer letters, contracts, and new-hire orientation programs. All necessary information needs to be appropriately conveyed to the employees, such as compensation, legal requirements, team acquisition, employee benefits, etc.\n",
            "The company's framework is based on its policies and procedures, which need to be followed and assessed from time to time.\n",
            "Such employment laws include:\n",
            "Employers need to act according to Occupational Safety and Health Act standards and verify for any safety issues in the workplace. All measures to support and safeguard human beings from various chemical and biological hazards used in companies should be included in the checklist.\n",
            "Substantial compliance can be ensured by providing an employee handbook and regularly updating it. This handbook can act as a communication tool to convey the organization's policies and procedures and how business should be conducted. It should be made a regular fundamental practice in companies for employees to sign their appropriate employment law papers' acknowledgment forms and receive a copy of an up-to-date employee handbook.\n",
            "The following policies and guidelines need to be addressed in the handbook:\n",
            "Certain social networking policies need to be implemented at the workplace, such as:\n",
            "It should be made mandatory for companies to hold sexual harassment training sessions to raise awareness and educate employees to take a hard stance against harassment and any kind of physical or emotional bullying. Drug-free workplace programs should also be implemented.\n",
            "This program can be implemented for personal assessment to improve teamwork, communication, and productivity among employees in the workplace. It can help determine whether the hired employees are people-oriented, multitaskers, hard-working, or detail-oriented.\n",
            "The company needs to offer management training focusing on the following concerns:\n",
            "It can also be known as an employee's eligibility form, which verifies the eligibility criteria for an employee to work in a particular company. \n",
            "officers need to collect, analyze and record these forms for every employee and contractor working for them.\n",
            "Files need to be provided by every employee in the company, which includes their application forms, recognition or disciplinary notices, and performance reviews. Documents related to medical issues, private or personal documents, polygraph results, background test results, or drug screening results can be avoided or kept separately in a confidential file.\n",
            "This involves the inclusion of benefits for employees who are dismissed due to performance reasons and exclusion of benefits for employees dismissed during the probationary period of 90 days or those dismissed due to code of conduct or leave without cause reasons.\n",
            "Working time can be defined as any time or hours that the employee spends working for the betterment of the company. This may include having meals, working overtime, working from home, time spent on traveling, or any other time spent performing duties of employment.\n",
            "All candidates aspiring to become an HR compliance officer must possess the following skills:\n",
            "A few HR compliance laws that every HR compliance officer should know about are:\n",
            "Compliance is the key to safety and ensures that the workplace is secure with the prevention of accidents or unfortunate events. Therefore, it is mandatory for employees to adhere to the policies put forward by the company and wisely follow them. Following the checklist given above, an HR compliance officer can make things easier.\n",
            "The Facts\n",
            "Q&A\n",
            "What is the role of HR compliance?\n",
            "Why is HR compliance mandatory?\n",
            "What is the significance of an HR compliance officer?\n",
            "HR Compliance Checklist\n",
            "Prerequisites for becoming an HR compliance officer\n",
            "The bottom line\n",
            "To ensure that the company implements best practices for its policies\n",
            "To help create manuals for hiring and retaining employees and assisting them in achieving superior performance\n",
            "To enhance the business's reputation\n",
            "To ensure the business systems are creating results\n",
            "To keep the business within the legalities of employment\n",
            "Recruiting and Interviewing\n",
            "Hiring Procedures\n",
            "Policies and Procedures\n",
            "Family and Medical Leave Act (FMLA)\n",
            "COBRA and unemployment benefits\n",
            "Pregnancy disability benefits and leave\n",
            "Health insurance benefits\n",
            "Drug and alcohol-free workplace specifications\n",
            "Rehabilitation services\n",
            "Equal pay\n",
            "Ergonomics issues\n",
            "Safety Section\n",
            "Employee Handbook\n",
            "Dress code rules include tattoos, extreme hair color, scents and aromas unpleasant or disturbing to others, distracting kind of body piercings, etc.\n",
            "Cellphone policies such as setting them to vibrate mode, avoidance of unnecessary phone calls and texts\n",
            "Social networking\n",
            "Cell phone usage policy includes texting and calling, taking pictures, and using social networking sites during working hours. \n",
            "An internet usage policy that includes acceptable online behavior, language, and exposure.\n",
            "Sexual Harassment, Bullying, and Drugs\n",
            "DiSC Program\n",
            "Management Training\n",
            "Counseling and dismissing employees\n",
            "Performance appraisals\n",
            "Managing difficult employees\n",
            "Training in diversity and harassment\n",
            "I-9 Forms\n",
            "Employee File\n",
            "Unemployment Benefits\n",
            "Working Time\n",
            "Prominent handling of compliance regulations\n",
            "Experience in risk management\n",
            "Knowledge of legal requirements and controls such as Anti-Money Laundering, or AML\n",
            "Awareness about industry practices and professional standards Excellent teamwork and communication skills\n",
            "Integrity and professional ethics \n",
            "The Fair Labor Standards Act (FLSA) defines employee exemption and non-exemption and establishes a minimum wage, overtime, and child labor laws.\n",
            "It is requisite for employers to maintain I-9 forms for confirmation that all employees are legally eligible to work in the U.S. under the Immigration Reform and Control Act (IRCA).\n",
            "The Employment Retirement Income Security Act (ERISA) specifies the required information that needs to be provided to employees participating in private health and pension plans sponsored by their employers.\n",
            "Affordable health care options need to be provided by large employers to their employees under the Affordable Care Act.\n",
            "The Consolidated Omnibus Budget Reconciliation Act (COBRA) covers insurance related to medical health for employees and their families for a certain period after they discontinue employment.\n",
            "compliance checklist\n",
            "HR compliance \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CwfNyLjfPsr",
        "outputId": "e5bb9688-316a-4fd0-9f2f-0e29ee227fec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DeferredList at 0x7c9fd04bbfd0 current result: []>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VfTw9l1kKIp"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}